
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a0f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ediapipe (/home/9826/.local/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install required packages\n",
    "!pip install torch torchvision torchaudio --quiet\n",
    "!pip install timm facenet-pytorch albumentations opencv-python mediapipe kagglehub scikit-learn --quiet\n",
    "!pip install --upgrade pip --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585bc96",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a98ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9685a04",
   "metadata": {},
   "source": [
    "## Dataset Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adb67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/9826/.cache/kagglehub/datasets/shuvoalok/raf-db-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Download RAF-DB via kagglehub\n",
    "dataset_path = kagglehub.dataset_download(\"shuvoalok/raf-db-dataset\")\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "data_root = os.path.join(dataset_path, 'DATASET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225ad5e",
   "metadata": {},
   "source": [
    "##  Define Label Mapping and Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fa41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Label Mapping and Constants\n",
    "\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    0: 'Surprise', \n",
    "    1: 'Fear',     \n",
    "    2: 'Happy',     \n",
    "    3: 'Sad',      \n",
    "    4: 'Angry',    \n",
    "    5: 'Neutral'   \n",
    "}\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2 \n",
    "NUM_CLASSES = 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6a02e",
   "metadata": {},
   "source": [
    "## Define Transforms (Standard ResNet Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5528db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/9826/.local/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Transforms (Standard ResNet Normalization)\n",
    "mean_vals = [0.485, 0.456, 0.406]\n",
    "std_vals = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.Blur(blur_limit=3, p=0.1),\n",
    "    A.Normalize(mean=mean_vals, std=std_vals),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=mean_vals, std=std_vals),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c1895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAFDataset(Dataset):\n",
    "    def __init__(self, root_dir, phase='train', transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, phase)\n",
    "        self.transform = transform\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # MAPPING (Skipping Disgust)\n",
    "        self.folder_to_label = {\n",
    "            '1': 0, # Surprise\n",
    "            '2': 1, # Fear\n",
    "            '4': 2, # Happy\n",
    "            '5': 3, # Sad\n",
    "            '6': 4, # Angry\n",
    "            '7': 5  # Neutral\n",
    "        }\n",
    "\n",
    "        # OVERSAMPLING CONFIG\n",
    "        # If the class is \"Fear\" (Folder 2) or \"Angry\" (Folder 6),\n",
    "        # we repeat the images X times to force the model to learn them.\n",
    "        self.oversample_factors = {\n",
    "            '2': 5,  # Fear: Repeat 5 times (Crucial!)\n",
    "            '6': 3,  # Angry: Repeat 3 times\n",
    "            '5': 2   # Sad: Repeat 2 times\n",
    "        }\n",
    "\n",
    "        # Load Images\n",
    "        available_folders = os.listdir(self.img_dir)\n",
    "        for folder_name in available_folders:\n",
    "            if folder_name in self.folder_to_label:\n",
    "                label_idx = self.folder_to_label[folder_name]\n",
    "                folder_path = os.path.join(self.img_dir, folder_name)\n",
    "\n",
    "                # Determine how many times to repeat this folder\n",
    "                # Default is 1 (no repeat)\n",
    "                repeat_count = self.oversample_factors.get(folder_name, 1)\n",
    "                if phase == 'test':\n",
    "                    repeat_count = 1  # Never oversample test data!\n",
    "\n",
    "                for img_file in os.listdir(folder_path):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                        full_path = os.path.join(folder_path, img_file)\n",
    "\n",
    "                        # THE HACK: Add the same file multiple times\n",
    "                        self.img_paths.extend([full_path] * repeat_count)\n",
    "                        self.labels.extend([label_idx] * repeat_count)\n",
    "\n",
    "        print(f\"Loaded {len(self.img_paths)} images for {phase} (With Oversampling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21455ae",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb99f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ResNet50 for 6 Classes...\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Model Initialization\n",
    "print(\"Initializing ResNet50 for 6 Classes...\")\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the final layer for 6 classes (Not 7)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54f25e",
   "metadata": {},
   "source": [
    "## Phase 1: Training Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 1: Training Head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 384/384 [00:44<00:00,  8.54it/s, acc=45.5, loss=1.47] \n",
      "Epoch 2/5: 100%|██████████| 384/384 [00:45<00:00,  8.38it/s, acc=50.4, loss=1.34] \n",
      "Epoch 3/5: 100%|██████████| 384/384 [00:44<00:00,  8.58it/s, acc=51.8, loss=1.31] \n",
      "Epoch 4/5: 100%|██████████| 384/384 [00:46<00:00,  8.35it/s, acc=52.2, loss=1.29] \n",
      "Epoch 5/5: 100%|██████████| 384/384 [00:44<00:00,  8.56it/s, acc=52.8, loss=1.27] \n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Phase 1 Training (Weighted Loss)\n",
    "\n",
    "# 1. CALCULATE CLASS WEIGHTS TO FIX IMBALANCE\n",
    "print(\"Calculating Class Weights to fix bias...\")\n",
    "# Extract all labels from the dataset\n",
    "y_train = train_dataset.labels\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# Calculate weights: Rare classes (Fear, Angry) get HIGHER weights\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Class Weights applied: {weights}\")\n",
    "# You should see high numbers for Fear/Angry and low for Happy/Neutral\n",
    "\n",
    "# 2. DEFINE LOSS WITH WEIGHTS\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "# Freeze body, train head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_epochs =  5\n",
    "print(\"Starting Phase 1: Training Head (With Weights)...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels) # Weighted Loss used here\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        loop.set_postfix(loss=running_loss/len(train_loader), acc=100.*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd7652",
   "metadata": {},
   "source": [
    "## Phase 2 Training (Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 2: Fine-Tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35: 100%|██████████| 384/384 [01:21<00:00,  4.71it/s, acc=68.4, loss=0.885]\n",
      "Epoch 2/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=79.7, loss=0.584]\n",
      "Epoch 3/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=83, loss=0.479]  \n",
      "Epoch 4/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=86.4, loss=0.385] \n",
      "Epoch 5/35: 100%|██████████| 384/384 [01:20<00:00,  4.76it/s, acc=88.2, loss=0.331] \n",
      "Epoch 6/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=89.7, loss=0.287] \n",
      "Epoch 7/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=91.5, loss=0.239] \n",
      "Epoch 8/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=92.3, loss=0.218] \n",
      "Epoch 9/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=93, loss=0.199]   \n",
      "Epoch 10/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=93.6, loss=0.182] \n",
      "Epoch 11/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=94.6, loss=0.157] \n",
      "Epoch 12/35: 100%|██████████| 384/384 [01:21<00:00,  4.74it/s, acc=94.3, loss=0.157] \n",
      "Epoch 13/35: 100%|██████████| 384/384 [01:21<00:00,  4.69it/s, acc=95.1, loss=0.139] \n",
      "Epoch 14/35: 100%|██████████| 384/384 [01:20<00:00,  4.75it/s, acc=95.6, loss=0.129] \n",
      "Epoch 15/35: 100%|██████████| 384/384 [01:20<00:00,  4.76it/s, acc=95.9, loss=0.115] \n",
      "Epoch 16/35: 100%|██████████| 384/384 [01:20<00:00,  4.77it/s, acc=95.9, loss=0.113] \n",
      "Epoch 17/35: 100%|██████████| 384/384 [00:53<00:00,  7.13it/s, acc=96.3, loss=0.108] \n",
      "Epoch 18/35: 100%|██████████| 384/384 [00:39<00:00,  9.67it/s, acc=96.2, loss=0.106] \n",
      "Epoch 19/35: 100%|██████████| 384/384 [00:39<00:00,  9.66it/s, acc=96.4, loss=0.104] \n",
      "Epoch 20/35: 100%|██████████| 384/384 [00:39<00:00,  9.65it/s, acc=96.9, loss=0.0899]\n",
      "Epoch 21/35: 100%|██████████| 384/384 [00:39<00:00,  9.65it/s, acc=96.7, loss=0.0975]\n",
      "Epoch 22/35: 100%|██████████| 384/384 [00:39<00:00,  9.66it/s, acc=96.6, loss=0.0926]\n",
      "Epoch 23/35: 100%|██████████| 384/384 [00:39<00:00,  9.67it/s, acc=96.8, loss=0.0877]\n",
      "Epoch 24/35: 100%|██████████| 384/384 [00:39<00:00,  9.68it/s, acc=97.2, loss=0.08]   \n",
      "Epoch 25/35: 100%|██████████| 384/384 [00:39<00:00,  9.65it/s, acc=96.9, loss=0.0913]\n",
      "Epoch 26/35: 100%|██████████| 384/384 [00:39<00:00,  9.66it/s, acc=97.3, loss=0.0775]\n",
      "Epoch 27/35: 100%|██████████| 384/384 [00:39<00:00,  9.67it/s, acc=97.4, loss=0.076] \n",
      "Epoch 28/35: 100%|██████████| 384/384 [00:39<00:00,  9.66it/s, acc=97.3, loss=0.0763]\n",
      "Epoch 29/35: 100%|██████████| 384/384 [00:39<00:00,  9.66it/s, acc=97.5, loss=0.0745]\n",
      "Epoch 30/35: 100%|██████████| 384/384 [00:39<00:00,  9.66it/s, acc=97.6, loss=0.0663]\n",
      "Epoch 31/35: 100%|██████████| 384/384 [00:39<00:00,  9.65it/s, acc=97.2, loss=0.0779]\n",
      "Epoch 32/35: 100%|██████████| 384/384 [00:39<00:00,  9.68it/s, acc=97.7, loss=0.0671]\n",
      "Epoch 33/35: 100%|██████████| 384/384 [00:39<00:00,  9.67it/s, acc=97.8, loss=0.0663]\n",
      "Epoch 34/35: 100%|██████████| 384/384 [00:39<00:00,  9.65it/s, acc=97.8, loss=0.065]  \n",
      "Epoch 35/35: 100%|██████████| 384/384 [00:39<00:00,  9.68it/s, acc=98, loss=0.0568]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Phase 2 Training (Fine-Tuning)\n",
    "print(\"Starting Phase 2: Fine-Tuning...\")\n",
    "\n",
    "# Unfreeze the last two blocks (layer3 and layer4)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer3' in name or 'layer4' in name or 'fc' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Use a much lower learning rate for fine-tuning\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "num_epochs = 35 \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        loop.set_postfix(loss=running_loss/len(train_loader), acc=100.*correct/total)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'rafdb_resnet50_6classes_weighted.pth')\n",
    "print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231240b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
