{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0ae3b6",
   "metadata": {},
   "source": [
    "## Load final saved model + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b0817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Loaded .pth weights into model: wavlm_ser_model.pth\n",
      "Labels: ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import torch\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "\n",
    "MODEL_DIR = os.path.abspath(\"wavlm_ser_model\")   # still needed for feat + labels (and as fallback config)\n",
    "PTH_PATH = os.path.join(\"wavlm_ser_model.pth\")\n",
    "\n",
    "assert os.path.isfile(PTH_PATH), f\".pth not found: {PTH_PATH}\"\n",
    "assert os.path.isdir(MODEL_DIR), f\"Model folder not found (needed for feat/labels): {MODEL_DIR}\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 1) Load feature extractor \n",
    "feat = AutoFeatureExtractor.from_pretrained(MODEL_DIR, local_files_only=True)\n",
    "\n",
    "# 2) Load labels + build mappings\n",
    "with open(os.path.join(MODEL_DIR, \"labels.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "label2id_pth = {lab:i for i, lab in enumerate(labels)}\n",
    "id2label_pth = {i:lab for lab,i in label2id_pth.items()}\n",
    "\n",
    "\n",
    "# 3) Rebuild model architecture EXACTLY (same backbone as training)\n",
    "model = AutoModelForAudioClassification.from_pretrained(MODEL_DIR, local_files_only=True)\n",
    "\n",
    "# 4) Load .pth weights\n",
    "state = torch.load(PTH_PATH, map_location=\"cpu\")\n",
    "missing, unexpected = model.load_state_dict(state, strict=True)\n",
    "\n",
    "# strict=True means it will error if mismatch\n",
    "model = model.to(device).eval()\n",
    "\n",
    "print(\"Loaded .pth weights into model:\", PTH_PATH)\n",
    "print(\"Labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc7398",
   "metadata": {},
   "source": [
    "## Choose the microphone device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf03fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT devices:\n",
      "[0] Microsoft Sound Mapper - Input | in_ch=2 | default_sr=44100.0\n",
      "[1] Mikrofon (4- Fifine Microphone) | in_ch=1 | default_sr=44100.0\n",
      "[2] Mikrofonarray (IntelÂ® Smart Sou | in_ch=4 | default_sr=44100.0\n",
      "[6] Primary Sound Capture Driver | in_ch=2 | default_sr=44100.0\n",
      "[7] Mikrofon (4- Fifine Microphone) | in_ch=1 | default_sr=44100.0\n",
      "[8] Mikrofonarray (IntelÂ® Smart Sound Technologie) | in_ch=4 | default_sr=44100.0\n",
      "[14] Mikrofon (4- Fifine Microphone) | in_ch=1 | default_sr=48000.0\n",
      "[15] Mikrofonarray (IntelÂ® Smart Sound Technologie) | in_ch=4 | default_sr=48000.0\n",
      "[16] Mikrofonarray (IntelÂ® Smart Sound Technologie Mikrofon) | in_ch=4 | default_sr=48000.0\n",
      "[19] PC-Lautsprecher (Realtek HD Audio 2nd output with SST) | in_ch=2 | default_sr=48000.0\n",
      "[22] PC-Lautsprecher (Realtek HD Audio output with SST) | in_ch=2 | default_sr=48000.0\n",
      "[23] Mikrofon (Realtek HD Audio Mic input) | in_ch=2 | default_sr=44100.0\n",
      "[24] Stereomix (Realtek HD Audio Stereo input) | in_ch=2 | default_sr=48000.0\n",
      "[26] Mikrofon (Fifine Microphone) | in_ch=1 | default_sr=44100.0\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "print(\"INPUT devices:\")\n",
    "for i, d in enumerate(sd.query_devices()):\n",
    "    if d[\"max_input_channels\"] > 0:\n",
    "        print(f\"[{i}] {d['name']} | in_ch={d['max_input_channels']} | default_sr={d['default_samplerate']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8b0f2",
   "metadata": {},
   "source": [
    "## Working RMS check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3041c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: Mikrofon (4- Fifine Microphone) | SR: 48000\n",
      "RMS: 1.912239938870525e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "MIC_INDEX = 14     # <-- your Fifine index that works\n",
    "dev = sd.query_devices(MIC_INDEX)\n",
    "SR = int(dev[\"default_samplerate\"])\n",
    "sd.default.device = (MIC_INDEX, None)\n",
    "\n",
    "print(\"Using:\", dev[\"name\"], \"| SR:\", SR)\n",
    "\n",
    "audio = sd.rec(int(SR*1.0), samplerate=SR, channels=1, dtype=\"float32\")\n",
    "sd.wait()\n",
    "rms = float(np.sqrt(np.mean(audio[:,0]**2) + 1e-12))\n",
    "print(\"RMS:\", rms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85070a",
   "metadata": {},
   "source": [
    "## Live utterance detection (mic SR) â†’ resample â†’ predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16c5f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:77: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:77: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\9826\\AppData\\Local\\Temp\\ipykernel_17604\\1898270382.py:77: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\"\\ LIVE MODE: say something with an emotion. Stop = Interrupt Kernel / Ctrl+C\\n\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mic: Mikrofon (4- Fifine Microphone) | mic SR: 48000\n",
      "Calibrating noise floor... stay silent for 1 second.\n",
      "Noise RMS: 0.000019\n",
      "Start_th: 0.005000 | End_th: 0.003000\n",
      "\\ LIVE MODE: say something with an emotion. Stop = Interrupt Kernel / Ctrl+C\n",
      "\n",
      "...speaking detected\n",
      "PRED: neutral=0.39 | surprise=0.23 | happy=0.19\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: neutral=0.33 | surprise=0.32 | happy=0.20\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: surprise=0.34 | neutral=0.28 | happy=0.21\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: surprise=0.66 | sad=0.14 | neutral=0.10\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: surprise=0.36 | neutral=0.30 | happy=0.19\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: happy=0.48 | fear=0.32 | sad=0.14\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: neutral=0.53 | surprise=0.21 | happy=0.12\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: happy=0.90 | fear=0.05 | neutral=0.02\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: fear=0.90 | happy=0.07 | sad=0.01\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: neutral=0.33 | surprise=0.31 | happy=0.21\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: angry=0.98 | fear=0.01 | happy=0.01\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: neutral=0.32 | surprise=0.32 | happy=0.21\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: fear=0.80 | sad=0.17 | happy=0.02\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "PRED: sad=0.85 | neutral=0.08 | fear=0.03\n",
      "\n",
      "ğŸ™ï¸ LISTENING... say it again\n",
      "\n",
      "...speaking detected\n",
      "\n",
      "Stopped.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import torchaudio\n",
    "import time\n",
    "\n",
    "MIC_INDEX = 14  # <-- your Fifine index that works\n",
    "sd.default.device = (MIC_INDEX, None)\n",
    "\n",
    "dev = sd.query_devices(MIC_INDEX)\n",
    "MIC_SR = int(dev[\"default_samplerate\"])\n",
    "print(\"Using mic:\", dev[\"name\"], \"| mic SR:\", MIC_SR)\n",
    "\n",
    "TARGET_SR = 16000  # model expects 16k\n",
    "\n",
    "BLOCK_SEC = 0.25\n",
    "BLOCK = int(MIC_SR * BLOCK_SEC)\n",
    "\n",
    "END_SILENCE_SEC = 0.8\n",
    "END_SILENCE_BLOCKS = max(1, int(END_SILENCE_SEC / BLOCK_SEC))\n",
    "MIN_UTT_SEC = 0.6\n",
    "MIN_UTT_LEN = int(MIC_SR * MIN_UTT_SEC)\n",
    "\n",
    "MAX_SECONDS = 6.0\n",
    "MAX_LEN = int(MIC_SR * MAX_SECONDS)\n",
    "\n",
    "START_MULT = 3.0\n",
    "END_MULT = 1.5\n",
    "\n",
    "def rms(x):\n",
    "    return float(np.sqrt(np.mean(x * x) + 1e-12))\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x)\n",
    "    e = np.exp(x)\n",
    "    return e / (np.sum(e) + 1e-12)\n",
    "\n",
    "def resample_to_16k(audio, sr):\n",
    "    if sr == TARGET_SR:\n",
    "        return audio.astype(np.float32)\n",
    "    w = torch.tensor(audio, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "    w = torchaudio.functional.resample(w, sr, TARGET_SR)\n",
    "    return w.squeeze(0).cpu().numpy().astype(np.float32)\n",
    "\n",
    "def predict(audio_mic_sr):\n",
    "    # normalize loudness\n",
    "    peak = np.max(np.abs(audio_mic_sr)) + 1e-9\n",
    "    audio_mic_sr = (audio_mic_sr / peak).astype(np.float32)\n",
    "\n",
    "    # truncate very long utterances\n",
    "    if len(audio_mic_sr) > MAX_LEN:\n",
    "        audio_mic_sr = audio_mic_sr[-MAX_LEN:]\n",
    "\n",
    "    audio_16k = resample_to_16k(audio_mic_sr, MIC_SR)\n",
    "\n",
    "    inputs = feat([audio_16k], sampling_rate=TARGET_SR, padding=True, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits[0].detach().cpu().numpy()\n",
    "\n",
    "    probs = softmax(logits)\n",
    "    top = np.argsort(-probs)[:3]\n",
    "    return [(labels[i], float(probs[i])) for i in top]\n",
    "\n",
    "# Calibrate noise floor\n",
    "print(\"Calibrating noise floor... stay silent for 1 second.\")\n",
    "calib = sd.rec(int(MIC_SR * 1.0), samplerate=MIC_SR, channels=1, dtype=\"float32\")\n",
    "sd.wait()\n",
    "noise = rms(calib[:, 0])\n",
    "\n",
    "start_th = max(0.005, noise * START_MULT)\n",
    "end_th   = max(0.003, noise * END_MULT)\n",
    "\n",
    "print(f\"Noise RMS: {noise:.6f}\")\n",
    "print(f\"Start_th: {start_th:.6f} | End_th: {end_th:.6f}\")\n",
    "print(\"\\ LIVE MODE: say something with an emotion. Stop = Interrupt Kernel / Ctrl+C\\n\")\n",
    "\n",
    "state = \"idle\"\n",
    "utter = []\n",
    "silence_blocks = 0\n",
    "\n",
    "stream = sd.InputStream(samplerate=MIC_SR, channels=1, dtype=\"float32\", blocksize=BLOCK)\n",
    "stream.start()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        block, _ = stream.read(BLOCK)\n",
    "        x = block[:, 0].copy()\n",
    "        r = rms(x)\n",
    "\n",
    "        if state == \"idle\":\n",
    "            if r > start_th:\n",
    "                state = \"rec\"\n",
    "                utter = [x]\n",
    "                silence_blocks = 0\n",
    "                print(\"...speaking detected\")\n",
    "        else:\n",
    "            utter.append(x)\n",
    "            if r < end_th:\n",
    "                silence_blocks += 1\n",
    "            else:\n",
    "                silence_blocks = 0\n",
    "\n",
    "            if silence_blocks >= END_SILENCE_BLOCKS:\n",
    "                audio = np.concatenate(utter, axis=0)\n",
    "\n",
    "                if len(audio) < MIN_UTT_LEN:\n",
    "                    print(\"Ignored very short sound.\")\n",
    "                else:\n",
    "                    top3 = predict(audio)\n",
    "                    print(\"PRED:\", \" | \".join([f\"{lab}={p:.2f}\" for lab, p in top3]))\n",
    "\n",
    "                print(\"\\nğŸ™ï¸ LISTENING... say it again\\n\")\n",
    "                state = \"idle\"\n",
    "                utter = []\n",
    "                silence_blocks = 0\n",
    "\n",
    "        time.sleep(0.01)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped.\")\n",
    "finally:\n",
    "    stream.stop()\n",
    "    stream.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae36000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
